# AI-powered Sign Language Video Translator
  ##  Overview
  
  The AI-powered Sign Language Video Translator is an innovative tool developed to bridge the communication gap between individuals who are deaf or hard of hearing and those who do not understand sign language. This project aims to provide a real-time translation of sign language into text, facilitating smoother and more inclusive interactions.
  Project Description
  
  This project utilizes advanced technologies such as MediaPipe and OpenCV for gesture recognition, and the Random Forest algorithm for classification. The system is designed not only to translate sign language gestures into text but also to offer additional functionalities like social media interactions including creating posts, adding comments, engaging in chats, browsing categories, and fingerspelling recognition.
  Objectives
  
      Real-Time Translation: Develop a system capable of translating sign language into text instantly, enhancing communication between the deaf community and others.
      High Accuracy: Achieve over 90% recognition accuracy in translating various sign language gestures, ensuring reliability and trustworthiness.
      User-Friendliness: Create an intuitive and accessible interface that can be easily used by individuals without technical expertise.
      Scalability and Adaptability: Build a scalable system that can accommodate more users and be adapted to include additional sign language variations.
      Timely Completion: Complete the project within the academic year, meeting all defined milestones and deadlines.

## Purpose

The primary goal of this project is to facilitate easier communication for people who use sign language by providing an immediate translation into written text. This tool aims to improve social interactions and inclusiveness, making communication more seamless in various settings such as everyday life, school, and work.
Scope

The project encompasses several phases:

    Planning: Define project goals, schedule timelines, and identify necessary resources.
    Design: Develop the system architecture, including both the user interface and backend processes.
    Development: Code the software, integrating gesture recognition tools and ensuring real-time data transmission.
    Testing: Conduct rigorous testing to ensure the system functions correctly under various conditions.
    Deployment: Deploy the system for user trials, gather feedback, and make necessary improvements.

## Features

    Real-Time Video Translation: Translate sign language gestures into text in real time.
    Chat Functionality: Engage in real-time conversations using text translated from sign language.
    Post Creation and Interaction: Create posts, add comments, and react to posts in a social media-like environment.
    Categories: Browse different categories of content, enhancing the user experience and engagement.
    Fingerspelling Recognition: Recognize and translate fingerspelling, aiding in the accurate translation of sign language.

## General Constraints

The development of this project faced several constraints, including:

    Data Availability: Limited availability of diverse sign language gesture datasets.
    Time Constraints: Strict deadlines within the academic year.
    Technical Limitations: Challenges in processing speed and accuracy under varied conditions using available tools.
    Budget Restrictions: Financial limitations impacting the procurement of advanced hardware or software.
    Scope Definition: Initial ambiguity in project scope leading to adjustments during the development process.
    User Diversity: Ensuring the system is accessible and usable by a diverse user base required multiple redesigns and testing sessions.

## Sample Screenshots

Here are some sample screenshots showcasing the various functionalities of the AI-powered Sign Language Video Translator:

### -Real-Time Translation 
![Picture10](https://github.com/mazenfarht/sign-language-website/assets/116845358/c9e5e244-88e6-4f48-afd2-f68909748aaf)
![Picture11](https://github.com/mazenfarht/sign-language-website/assets/116845358/2703dc89-55a0-4718-9604-00c4e1be8cd6)
![Picture9](https://github.com/mazenfarht/sign-language-website/assets/116845358/361af769-f59a-4e92-986c-12e236eb711e)
![Picture2](https://github.com/mazenfarht/sign-language-website/assets/116845358/b8632dff-05f8-4231-92ce-ce77e05ddb57)




### -Chat Interface
![Picture7](https://github.com/mazenfarht/sign-language-website/assets/116845358/dc860f2f-7b7d-43a9-9cb4-0717f2dd920f)


### -Post Creation and Interaction
![Picture6](https://github.com/mazenfarht/sign-language-website/assets/116845358/f2fe2372-8621-4ce3-b633-a2868860672a)
![Picture6](https://github.com/mazenfarht/sign-language-website/assets/116845358/04fbe1d9-8d6c-4200-9620-db68ed964856)



### -Category Browsing
![Picture5](https://github.com/mazenfarht/sign-language-website/assets/116845358/e5ecbb83-9f2b-4fcb-9c67-5a2c5eef8bb2)


### -Fingerspelling Recognition
![Picture15](https://github.com/mazenfarht/sign-language-website/assets/116845358/ba23b02c-51d9-4a3d-bd5e-db02e2adf5f7)


## Conclusion

The AI-powered Sign Language Video Translator project is not only a technical achievement but also a significant step towards enhancing social inclusiveness and communication for the deaf and hard of hearing community. By providing real-time translation and additional social media functionalities, this project aims to make a positive impact on the lives of many people.
